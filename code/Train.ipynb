{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y\")\n",
    "global_path = \"../models/\"\n",
    "bin_path = \".bin\"\n",
    "model_path = \".model\"\n",
    "txt_path = \".txt\"\n",
    "path_ft =  global_path + \"ft_\"+ dt_string + bin_path\n",
    "path_w2v =  global_path + \"w2v_\"+ dt_string + model_path\n",
    "path_glove = global_path + \"gloVe_\"+ dt_string + txt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/gloVe_13-05-2020.txt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_unsupervised('../data/trainFile.txt',thread=4,epoch=9,dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to save the vectors at it will cost less storage space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from fasttext import load_model\n",
    "\n",
    "# original BIN model loading\n",
    "f = load_model('../models/ft_13-05-2020.bin')\n",
    "lines=[]\n",
    "\n",
    "# get all words from model\n",
    "words = f.get_words()\n",
    "\n",
    "with open('../models/ft_13-05-2020.txt','w') as file_out:\n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = f.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/ft_14-05-2020.bin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ../models/ft_13-05-2020.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/merge') as f:\n",
    "    corpus = f.readlines()\n",
    "res = []\n",
    "for sent in corpus: \n",
    "    sent = sent[0:len(sent)-1]\n",
    "    res.append(sent.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(res, size=300,window=5,negative=10, alpha=0.01,iter=9,\n",
    "                 min_count=5, workers=4,sg=1,compute_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "path = get_tmpfile(path_w2v)\n",
    "model.save(path_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove \n",
    "Adjust Path to your local GloVe Repo\n",
    "https://github.com/stanfordnlp/GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/home/c3dric/Uni/Studium/master/ss20/projet-specifique/code/merge': No such file or directory\n",
      "\n",
      "$ build/vocab_count -min-count 5 -verbose 2 < press_all_glove.txt > vocab.txt\n",
      "BUILDING VOCABULARY\n",
      "Processed 0 tokens.\u001b[11G100000 tokens.\u001b[11G200000 tokens.\u001b[11G300000 tokens.\u001b[11G400000 tokens.\u001b[11G500000 tokens.\u001b[11G600000 tokens.\u001b[11G700000 tokens.\u001b[11G800000 tokens.\u001b[11G900000 tokens.\u001b[11G1000000 tokens.\u001b[11G1100000 tokens.\u001b[11G1200000 tokens.\u001b[11G1300000 tokens.\u001b[11G1400000 tokens.\u001b[11G1500000 tokens.\u001b[11G1600000 tokens.\u001b[11G1700000 tokens.\u001b[11G1800000 tokens.\u001b[11G1900000 tokens.\u001b[11G2000000 tokens.\u001b[11G2100000 tokens.\u001b[11G2200000 tokens.\u001b[11G2300000 tokens.\u001b[11G2400000 tokens.\u001b[11G2500000 tokens.\u001b[11G2600000 tokens.\u001b[11G2700000 tokens.\u001b[11G2800000 tokens.\u001b[11G2900000 tokens.\u001b[11G3000000 tokens.\u001b[11G3100000 tokens.\u001b[11G3200000 tokens.\u001b[11G3300000 tokens.\u001b[11G3400000 tokens.\u001b[11G3500000 tokens.\u001b[11G3600000 tokens.\u001b[11G3700000 tokens.\u001b[11G3800000 tokens.\u001b[11G3900000 tokens.\u001b[11G4000000 tokens.\u001b[11G4100000 tokens.\u001b[11G4200000 tokens.\u001b[11G4300000 tokens.\u001b[11G4400000 tokens.\u001b[11G4500000 tokens.\u001b[11G4600000 tokens.\u001b[11G4700000 tokens.\u001b[11G4800000 tokens.\u001b[11G4900000 tokens.\u001b[11G5000000 tokens.\u001b[11G5100000 tokens.\u001b[11G5200000 tokens.\u001b[11G5300000 tokens.\u001b[11G5400000 tokens.\u001b[11G5500000 tokens.\u001b[11G5600000 tokens.\u001b[11G5700000 tokens.\u001b[11G5800000 tokens.\u001b[11G5900000 tokens.\u001b[11G6000000 tokens.\u001b[11G6100000 tokens.\u001b[11G6200000 tokens.\u001b[11G6300000 tokens.\u001b[11G6400000 tokens.\u001b[11G6500000 tokens.\u001b[11G6600000 tokens.\u001b[11G6700000 tokens.\u001b[11G6800000 tokens.\u001b[11G6900000 tokens.\u001b[11G7000000 tokens.\u001b[11G7100000 tokens.\u001b[11G7200000 tokens.\u001b[11G7300000 tokens.\u001b[11G7400000 tokens.\u001b[11G7500000 tokens.\u001b[11G7600000 tokens.\u001b[11G7700000 tokens.\u001b[11G7800000 tokens.\u001b[11G7900000 tokens.\u001b[11G8000000 tokens.\u001b[11G8100000 tokens.\u001b[11G8200000 tokens.\u001b[0GProcessed 8294465 tokens.\n",
      "Counted 130262 unique words.\n",
      "Truncating vocabulary at min count 5.\n",
      "Using vocabulary of size 40632.\n",
      "\n",
      "$ build/cooccur -memory 14.0 -vocab-file vocab.txt -verbose 2 -window-size 15 < press_all_glove.txt > cooccurrence.bin\n",
      "COUNTING COOCCURRENCES\n",
      "window size: 15\n",
      "context: symmetric\n",
      "max product: 44928007\n",
      "overflow length: 133099246\n",
      "Reading vocab from file \"vocab.txt\"...loaded 40632 words.\n",
      "Building lookup table...table contains 206811393 elements.\n",
      "Processing token: 0\u001b[19G100000\u001b[19G200000\u001b[19G300000\u001b[19G400000\u001b[19G500000\u001b[19G600000\u001b[19G700000\u001b[19G800000\u001b[19G900000\u001b[19G1000000^C\n"
     ]
    }
   ],
   "source": [
    "! cp merge ~/Programming/GloVe/press_all_glove.txt\n",
    "! cd  ~/Programming/GloVe/; sh ~/Programming/GloVe/demo.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
